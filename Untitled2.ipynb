{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1zVncIXUbTgKm2nAG7uIG8CnqEzMetXAm",
      "authorship_tag": "ABX9TyNbGRSLZ42+PpSwVDpUzeAQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyiparlakoglu/tf-05-06/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AkX-MRlklmMz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "target_size = (image_size, image_size)\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 30"
      ],
      "metadata": {
        "id": "96f3rT-ZluCY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = \"../content/drive/MyDrive/yenidata\"\n",
        "train_dir = os.path.join(base_dir,\"train\")\n",
        "test_dir = os.path.join(base_dir,\"test\")\n",
        "predict_dir = os.path.join(base_dir, \"predict\")"
      ],
      "metadata": {
        "id": "3p-VUXEAlxAR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0,\n",
        "                                                             shear_range = 0.2,\n",
        "                                                             zoom_range = 0.2,\n",
        "                                                             width_shift_range = 0.2,\n",
        "                                                             height_shift_range = 0.2,\n",
        "                                                             fill_mode=\"nearest\")\n",
        "\n",
        "test_datagen = keras.preprocessing.image.ImageDataGenerator(rescale = 1/255.0)"
      ],
      "metadata": {
        "id": "c47iCPGDl1sI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size = (image_size, image_size),\n",
        "                                              \n",
        "                                               class_mode = \"categorical\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size = (image_size, image_size),\n",
        "                                            \n",
        "                                             class_mode = \"categorical\")\n"
      ],
      "metadata": {
        "id": "uvZk-HGzl4Et",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1b2417d-9529-4efb-eb9f-9f8d24be15ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 240 images belonging to 3 classes.\n",
            "Found 60 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = list(train_data.class_indices.keys())\n",
        "print(train_data.class_indices)"
      ],
      "metadata": {
        "id": "VjM_qHuBqC65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0ba753-9643-4a6c-c0d9-b3167a29aabb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bac': 0, 'healthy': 1, 'late': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('class_indices.json','w') as f:\n",
        "  json.dump(train_data.class_indices, f)\n",
        "\n",
        "from IPython.display import FileLink\n",
        "FileLink(r'class_indices.json')"
      ],
      "metadata": {
        "id": "At6NyTVBqHvH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba8ec0d8-7a81-40b9-f03f-4732bdae61be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "/content/class_indices.json"
            ],
            "text/html": [
              "<a href='class_indices.json' target='_blank'>class_indices.json</a><br>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNet(weights = \"imagenet\",\n",
        "                                             include_top = False,\n",
        "                                             input_shape = input_shape)\n",
        "\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "bTePQqnOqJ66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8925275c-610a-440d-ac30-38da47a5a794"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "17235968/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape = input_shape)\n",
        "\n",
        "x = base_model(inputs, training = False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(len(categories), \n",
        "                          activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs = inputs, \n",
        "                    outputs = x, \n",
        "                    name=\"LeafDisease_MobileNet\")"
      ],
      "metadata": {
        "id": "imSgI9DlqMQV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = False),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
        "                       'accuracy'])"
      ],
      "metadata": {
        "id": "HaIIkkQrqOQJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                    validation_data=test_data,\n",
        "                    epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AU_4XrJEqQJZ",
        "outputId": "d8dc3754-f0fc-477d-c63f-aaac02916824"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 62s 8s/step - loss: 1.2387 - categorical_accuracy: 0.3958 - accuracy: 0.3958 - val_loss: 0.9285 - val_categorical_accuracy: 0.6000 - val_accuracy: 0.6000\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.9598 - categorical_accuracy: 0.4917 - accuracy: 0.4917 - val_loss: 0.7448 - val_categorical_accuracy: 0.7667 - val_accuracy: 0.7667\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.8324 - categorical_accuracy: 0.6542 - accuracy: 0.6542 - val_loss: 0.6494 - val_categorical_accuracy: 0.7667 - val_accuracy: 0.7667\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.6719 - categorical_accuracy: 0.7208 - accuracy: 0.7208 - val_loss: 0.5921 - val_categorical_accuracy: 0.8000 - val_accuracy: 0.8000\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.6448 - categorical_accuracy: 0.7167 - accuracy: 0.7167 - val_loss: 0.5011 - val_categorical_accuracy: 0.8667 - val_accuracy: 0.8667\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 20s 2s/step - loss: 0.5735 - categorical_accuracy: 0.7667 - accuracy: 0.7667 - val_loss: 0.4475 - val_categorical_accuracy: 0.8500 - val_accuracy: 0.8500\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.4871 - categorical_accuracy: 0.8167 - accuracy: 0.8167 - val_loss: 0.4253 - val_categorical_accuracy: 0.8167 - val_accuracy: 0.8167\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.4419 - categorical_accuracy: 0.8083 - accuracy: 0.8083 - val_loss: 0.3875 - val_categorical_accuracy: 0.9333 - val_accuracy: 0.9333\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.4249 - categorical_accuracy: 0.8250 - accuracy: 0.8250 - val_loss: 0.3596 - val_categorical_accuracy: 0.9333 - val_accuracy: 0.9333\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.4055 - categorical_accuracy: 0.8500 - accuracy: 0.8500 - val_loss: 0.3317 - val_categorical_accuracy: 0.9333 - val_accuracy: 0.9333\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3603 - categorical_accuracy: 0.8792 - accuracy: 0.8792 - val_loss: 0.3087 - val_categorical_accuracy: 0.9333 - val_accuracy: 0.9333\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3517 - categorical_accuracy: 0.8875 - accuracy: 0.8875 - val_loss: 0.2943 - val_categorical_accuracy: 0.9667 - val_accuracy: 0.9667\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3074 - categorical_accuracy: 0.9042 - accuracy: 0.9042 - val_loss: 0.2887 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3144 - categorical_accuracy: 0.8917 - accuracy: 0.8917 - val_loss: 0.2726 - val_categorical_accuracy: 0.9667 - val_accuracy: 0.9667\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.3215 - categorical_accuracy: 0.8833 - accuracy: 0.8833 - val_loss: 0.2672 - val_categorical_accuracy: 0.9667 - val_accuracy: 0.9667\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2730 - categorical_accuracy: 0.9250 - accuracy: 0.9250 - val_loss: 0.2570 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2965 - categorical_accuracy: 0.9042 - accuracy: 0.9042 - val_loss: 0.2447 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2763 - categorical_accuracy: 0.9000 - accuracy: 0.9000 - val_loss: 0.2395 - val_categorical_accuracy: 0.9500 - val_accuracy: 0.9500\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2672 - categorical_accuracy: 0.9083 - accuracy: 0.9083 - val_loss: 0.2274 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 20s 3s/step - loss: 0.2390 - categorical_accuracy: 0.9292 - accuracy: 0.9292 - val_loss: 0.2283 - val_categorical_accuracy: 1.0000 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2363 - categorical_accuracy: 0.9167 - accuracy: 0.9167 - val_loss: 0.2199 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2425 - categorical_accuracy: 0.9417 - accuracy: 0.9417 - val_loss: 0.2113 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2345 - categorical_accuracy: 0.9333 - accuracy: 0.9333 - val_loss: 0.2070 - val_categorical_accuracy: 1.0000 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2279 - categorical_accuracy: 0.9208 - accuracy: 0.9208 - val_loss: 0.1982 - val_categorical_accuracy: 0.9667 - val_accuracy: 0.9667\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2026 - categorical_accuracy: 0.9583 - accuracy: 0.9583 - val_loss: 0.1944 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2223 - categorical_accuracy: 0.9333 - accuracy: 0.9333 - val_loss: 0.1886 - val_categorical_accuracy: 1.0000 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 19s 2s/step - loss: 0.1942 - categorical_accuracy: 0.9333 - accuracy: 0.9333 - val_loss: 0.1884 - val_categorical_accuracy: 1.0000 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.1949 - categorical_accuracy: 0.9458 - accuracy: 0.9458 - val_loss: 0.1871 - val_categorical_accuracy: 0.9500 - val_accuracy: 0.9500\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.2163 - categorical_accuracy: 0.9125 - accuracy: 0.9125 - val_loss: 0.1809 - val_categorical_accuracy: 0.9833 - val_accuracy: 0.9833\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 18s 2s/step - loss: 0.1760 - categorical_accuracy: 0.9667 - accuracy: 0.9667 - val_loss: 0.1794 - val_categorical_accuracy: 0.9500 - val_accuracy: 0.9500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('plant_disease_2')"
      ],
      "metadata": {
        "id": "3FNxnH_9sHCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b788f5b6-fdff-480a-d807-1f9ec49226d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: plant_disease_2/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_data = test_datagen.flow_from_directory(predict_dir,\n",
        "                                             target_size = (image_size, image_size),\n",
        "                                            \n",
        "                                             class_mode = \"categorical\")"
      ],
      "metadata": {
        "id": "PMw_aVGtsZ5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc8868b-864c-4313-c1df-efe0db36ecea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(predict_data)"
      ],
      "metadata": {
        "id": "XDZgCDumtFnj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result =  np.argmax(prediction, axis=1)\n",
        "result"
      ],
      "metadata": {
        "id": "aNOsClrstmlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eaba942-e0a0-4fc7-bd19-56aef861a376"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories"
      ],
      "metadata": {
        "id": "dxnCssUVvxRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d625787f-fbd0-4e94-cb2c-4420c953ed10"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bac', 'healthy', 'late']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "M5zMjxJh3xve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c3f9f8-1c9c-414f-c29c-8e05217e9849"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6724962 , 0.06651988, 0.26098394],\n",
              "       [0.57599545, 0.18086578, 0.24313876],\n",
              "       [0.5713071 , 0.22503726, 0.20365559]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(categories[np.argmax(prediction[0])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dp6u5_tBXevE",
        "outputId": "979af723-3323-4bbb-f614-b2ec798f67b2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bac\n"
          ]
        }
      ]
    }
  ]
}